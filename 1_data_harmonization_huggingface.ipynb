{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoritzLaurer/zeroshot-classifier/blob/main/1_data_harmonization_huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and harmonize multiple datasets from the Hugging Face hub\n"
      ],
      "metadata": {
        "id": "nG2wMl90mp1A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIUmuq4kHxK-"
      },
      "source": [
        "### Install and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gVfUS7Fn84zR"
      },
      "outputs": [],
      "source": [
        "!pip install datasets~=2.14.0 -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4uYxbLh9k3_"
      },
      "outputs": [],
      "source": [
        "## load packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab.data_table import DataTable\n",
        "from google.colab import data_table\n",
        "from IPython.display import display\n",
        "data_table.enable_dataframe_formatter() # https://colab.research.google.com/notebooks/data_table.ipynb#scrollTo=JgBtx0xFFv_i\n",
        "\n",
        "# set global seed for reproducibility and against seed hacking\n",
        "SEED_GLOBAL = 42\n",
        "np.random.seed(SEED_GLOBAL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seADcw_RTSlF"
      },
      "outputs": [],
      "source": [
        "## connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "#set wd\n",
        "print(os.getcwd())\n",
        "os.chdir(\"/content/drive/My Drive/PhD/zero-shot-models\")\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5FqRJPsTPhD"
      },
      "source": [
        "### Download and harmonize datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FLzJ9ivfIcY"
      },
      "source": [
        "#### Well-formed query dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2a7Hevlg8Tf"
      },
      "outputs": [],
      "source": [
        "dataset_wellformedquery = load_dataset(\"google_wellformed_query\")\n",
        "print(\"Raw dataset structure:\\n\", dataset_wellformedquery)\n",
        "\n",
        "def prompt_format_wellformed_query(label):\n",
        "    if label >= 0.75:\n",
        "        label_text = \"well_formed\"\n",
        "    elif label <= 0.35:\n",
        "        label_text = \"not_well_formed\"\n",
        "    else:\n",
        "        label_text = np.nan\n",
        "\n",
        "    return label_text\n",
        "\n",
        "\n",
        "## prepare df_train\n",
        "df_wellformedquery_train = pd.concat([\n",
        "    dataset_wellformedquery[\"train\"].to_pandas(),\n",
        "    dataset_wellformedquery[\"validation\"].to_pandas()\n",
        "])\n",
        "\n",
        "df_wellformedquery_train[\"label_text\"] = df_wellformedquery_train.rating.apply(prompt_format_wellformed_query)\n",
        "\n",
        "# remove na\n",
        "df_wellformedquery_train = df_wellformedquery_train[~pd.isna(df_wellformedquery_train.label_text)]\n",
        "\n",
        "# remove duplicates\n",
        "df_wellformedquery_train = df_wellformedquery_train.rename(columns={\"content\": \"text\"})\n",
        "df_wellformedquery_train = df_wellformedquery_train[~df_wellformedquery_train.text.duplicated()]\n",
        "\n",
        "# create standard label column\n",
        "df_wellformedquery_train[\"label_standard\"] = df_wellformedquery_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_wellformedquery_train))\n",
        "n_data_per_label = 10_000\n",
        "df_wellformedquery_train = df_wellformedquery_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length after downsampling: \", len(df_wellformedquery_train))\n",
        "\n",
        "# final harmonized format\n",
        "df_wellformedquery_train = df_wellformedquery_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_wellformedquery_train.label_text.value_counts())\n",
        "display(df_wellformedquery_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOgt1xsVg8Tg"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "df_wellformedquery_test = dataset_wellformedquery[\"test\"].to_pandas()\n",
        "df_wellformedquery_test[\"label_text\"] = df_wellformedquery_test.rating.apply(prompt_format_wellformed_query)\n",
        "df_wellformedquery_test = df_wellformedquery_test[~pd.isna(df_wellformedquery_test.label_text)]\n",
        "df_wellformedquery_test = df_wellformedquery_test.rename(columns={\"content\": \"text\"})\n",
        "df_wellformedquery_test[\"label_standard\"] = df_wellformedquery_test.label_text.factorize(sort=True)[0]\n",
        "df_wellformedquery_test = df_wellformedquery_test[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "display(df_wellformedquery_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARdn3Kfrg8Tg"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"wellformedquery\"\n",
        "df_wellformedquery_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_wellformedquery_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymiaMQLgnnOn"
      },
      "source": [
        "#### Social bias frames dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WFqIdyOnqA4"
      },
      "outputs": [],
      "source": [
        "# dataset https://huggingface.co/datasets/social_bias_frames\n",
        "# explanation of variables https://huggingface.co/datasets/social_bias_frames#default-1\n",
        "\n",
        "from datasets import Dataset, DatasetDict, concatenate_datasets\n",
        "import html\n",
        "\n",
        "dataset_bias_frames = load_dataset(\"social_bias_frames\")\n",
        "print(\"Raw dataset structure:\\n\", dataset_bias_frames)\n",
        "\n",
        "# concatenate train and validation split\n",
        "dataset_bias_frames[\"train\"] = concatenate_datasets([dataset_bias_frames[\"train\"], dataset_bias_frames[\"validation\"]])\n",
        "\n",
        "# average annotations of 3 annotators per text\n",
        "dataset_bias_frames_mean = DatasetDict()\n",
        "for split in [\"train\", \"test\"]:\n",
        "    df_bias_frames = dataset_bias_frames[split].to_pandas()\n",
        "\n",
        "    # convert relevant column to numeric to enable aggregation\n",
        "    columns_to_convert = ['intentYN', 'sexYN', 'offensiveYN', 'whoTarget', 'speakerMinorityYN']\n",
        "    df_bias_frames[columns_to_convert] = df_bias_frames[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    # aggregate judgement of different annotators\n",
        "    df_bias_frames_mean = df_bias_frames.groupby(\"post\", as_index=False, group_keys=False)[\n",
        "        [\"intentYN\", \"sexYN\", \"offensiveYN\",'whoTarget', \"speakerMinorityYN\"]\n",
        "        ].mean(numeric_only=True).reset_index(drop=True)\n",
        "\n",
        "    # clean html tags\n",
        "    #df_bias_frames['post'] = df_bias_frames['post'].apply(html.unescape)\n",
        "\n",
        "    dataset_bias_frames_mean[split] = Dataset.from_pandas(df_bias_frames_mean)\n",
        "\n",
        "print(dataset_bias_frames_mean)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2tksCx72l6d"
      },
      "outputs": [],
      "source": [
        "# decide on binary label based on threshold\n",
        "\n",
        "def prompt_format_bias_frames(example, column_label=None, label_text=None):\n",
        "    if (example[column_label] is np.nan) or (example[column_label] is None):\n",
        "        label = np.nan\n",
        "        label_text = None\n",
        "    elif example[column_label] >= 0.70:\n",
        "        label = 1\n",
        "        label_text = label_text\n",
        "    elif example[column_label] <= 0.30:\n",
        "        label = 0\n",
        "        label_text = \"not_\" + label_text\n",
        "    else:\n",
        "        label = np.nan\n",
        "        label_text = None\n",
        "\n",
        "    # remove HTML tags\n",
        "    text = html.unescape(example[\"post\"])\n",
        "\n",
        "    return {\"text\": text, \"label_text\": label_text, \"label_standard\": label}\n",
        "\n",
        "# create cleaned datasets for each subtask\n",
        "dataset_bias_frames_dic = {}\n",
        "for task in [\"sexYN\", \"intentYN\", \"offensiveYN\"]:\n",
        "    label_text = task.replace(\"YN\", \"\")\n",
        "    dataset_bias_frames_mean_task = dataset_bias_frames_mean.map(\n",
        "        lambda example: prompt_format_bias_frames(example, column_label=task, label_text=label_text)\n",
        "    )\n",
        "    columns_to_remove = [col for col in dataset_bias_frames_mean_task[\"train\"].column_names if col not in [\"text\", \"label_text\", \"label_standard\"]]\n",
        "    dataset_bias_frames_mean_task = dataset_bias_frames_mean_task.remove_columns(columns_to_remove)\n",
        "\n",
        "    # remove nans\n",
        "    dataset_bias_frames_mean_task = dataset_bias_frames_mean_task.filter(lambda example: not np.isnan(example['label_standard']))\n",
        "    #dataset_bias_frames_mean_task = dataset_bias_frames_mean_task.shuffle(seed=SEED_GLOBAL)\n",
        "\n",
        "    # downsample\n",
        "    dataset_bias_frames_mean_task_dic = {}\n",
        "    for split in [\"train\", \"test\"]:\n",
        "        print(\"Dataset length before downsampling: \", len(dataset_bias_frames_mean_task[split]))\n",
        "        n_data_per_label = 10_000\n",
        "        df_bias_frames_mean_task_split = dataset_bias_frames_mean_task[split].to_pandas().groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "            lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        "        )\n",
        "        print(\"Dataset length after downsampling: \", len(df_bias_frames_mean_task_split))\n",
        "        # shuffle\n",
        "        df_bias_frames_mean_task_split = df_bias_frames_mean_task_split.sample(frac=1, random_state=SEED_GLOBAL)\n",
        "        # back to dataset\n",
        "        dataset_bias_frames_mean_task_dic.update({split: Dataset.from_pandas(df_bias_frames_mean_task_split.reset_index(drop=True))})\n",
        "    dataset_bias_frames_mean_task = DatasetDict(dataset_bias_frames_mean_task_dic)\n",
        "\n",
        "    # label_standard to int\n",
        "    dataset_bias_frames_mean_task = dataset_bias_frames_mean_task.map(lambda x: {\"label_standard\": int(x[\"label_standard\"])})\n",
        "\n",
        "    print(\"Dataset for task: \", task)\n",
        "    print(dataset_bias_frames_mean_task)\n",
        "    print(\"Label distribution in train:\\n\", dataset_bias_frames_mean_task[\"train\"].to_pandas().label_text.value_counts())\n",
        "    print(\"\\n\")\n",
        "\n",
        "    dataset_bias_frames_dic.update({label_text: dataset_bias_frames_mean_task})\n",
        "\n",
        "print(\"Full dataset structure:\\n\", dataset_bias_frames_dic, \"\\n\")\n",
        "\n",
        "print(\"Offensive dataset example: \")\n",
        "display(dataset_bias_frames_dic[\"offensive\"][\"train\"].to_pandas().head(100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deletable test\n",
        "#dataset_bias_frames_dic[\"sex\"][\"train\"].to_pandas().label_standard.value_counts()\n",
        "#dataset_bias_frames_dic[\"sex\"][\"train\"].to_pandas().label_standard.dtype"
      ],
      "metadata": {
        "id": "ujzMujMTaRDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"biasframes\"\n",
        "for key_task, value_dataset in dataset_bias_frames_dic.items():\n",
        "    df_bias_frames_task_train = dataset_bias_frames_dic[key_task][\"train\"].to_pandas()\n",
        "    df_bias_frames_task_test = dataset_bias_frames_dic[key_task][\"test\"].to_pandas()\n",
        "    # label to int. is float for some reason\n",
        "    df_bias_frames_task_train[\"label_standard\"] = df_bias_frames_task_train.label_standard.apply(int)\n",
        "    df_bias_frames_task_test[\"label_standard\"] = df_bias_frames_task_test.label_standard.apply(int)\n",
        "    # remove html tags, didn't work above in dataset?\n",
        "    df_bias_frames_task_train['text'] = df_bias_frames_task_train['text'].apply(html.unescape)\n",
        "    df_bias_frames_task_test['text'] = df_bias_frames_task_test['text'].apply(html.unescape)\n",
        "    # to disk\n",
        "    df_bias_frames_task_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_{key_task}_train.gzip\", compression='gzip')\n",
        "    df_bias_frames_task_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_{key_task}_test.gzip\", compression='gzip')"
      ],
      "metadata": {
        "id": "Wx00TcCTUCxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNDMxXus71R_"
      },
      "source": [
        "#### Financial phrasebank dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBpqWQlmML64"
      },
      "outputs": [],
      "source": [
        "dataset_financialphrasebank = load_dataset(\"financial_phrasebank\", \"sentences_75agree\")\n",
        "# only has train split\n",
        "print(\"Raw dataset structure:\\n\", dataset_financialphrasebank)\n",
        "\n",
        "label_mapping_financialphrasebank = {\n",
        "    idx: name for idx, name in enumerate(dataset_financialphrasebank[\"train\"].features[\"label\"].names)\n",
        "}\n",
        "\n",
        "## prepare df_train\n",
        "df_financialphrasebank_train = dataset_financialphrasebank[\"train\"].to_pandas()\n",
        "\n",
        "\n",
        "df_financialphrasebank_train[\"label_text\"] = df_financialphrasebank_train.label.map(label_mapping_financialphrasebank)\n",
        "\n",
        "df_financialphrasebank_train = df_financialphrasebank_train.rename(columns={\"sentence\": \"text\"})\n",
        "df_financialphrasebank_train = df_financialphrasebank_train[~df_financialphrasebank_train.text.duplicated()]\n",
        "\n",
        "df_financialphrasebank_train[\"label_standard\"] = df_financialphrasebank_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_financialphrasebank_train))\n",
        "n_data_per_label = 10_000\n",
        "df_financialphrasebank_train = df_financialphrasebank_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length before downsampling: \", len(df_financialphrasebank_train))\n",
        "\n",
        "# final harmonized format\n",
        "df_financialphrasebank_train = df_financialphrasebank_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_financialphrasebank_train.label_text.value_counts())\n",
        "display(df_financialphrasebank_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcy-zXU8ML65"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "# no test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_financialphrasebank_train_split, df_financialphrasebank_test_split = train_test_split(\n",
        "    df_financialphrasebank_train, test_size=0.2, random_state=SEED_GLOBAL,\n",
        "    shuffle=True, stratify=df_financialphrasebank_train[\"label_text\"]\n",
        ")\n",
        "print(len(df_financialphrasebank_train_split))\n",
        "print(len(df_financialphrasebank_test_split))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLQXuJAjML65"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"financialphrasebank\"\n",
        "df_financialphrasebank_train_split.reset_index(drop=True).to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_financialphrasebank_test_split.reset_index(drop=True).to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqwxbizeGTD1"
      },
      "source": [
        "#### Rotten Tomatoes dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYPpoZnHLNoY"
      },
      "outputs": [],
      "source": [
        "dataset_rottentomatoes = load_dataset(\"rotten_tomatoes\")\n",
        "print(\"Raw dataset structure:\\n\", dataset_rottentomatoes)\n",
        "\n",
        "label_mapping_rottentomatoes = {\n",
        "    idx: name for idx, name in enumerate(dataset_rottentomatoes[\"train\"].features[\"label\"].names)\n",
        "}\n",
        "\n",
        "## prepare df_train\n",
        "df_rottentomatoes_train = pd.concat([\n",
        "    dataset_rottentomatoes[\"train\"].to_pandas(),\n",
        "    dataset_rottentomatoes[\"validation\"].to_pandas()\n",
        "])\n",
        "\n",
        "df_rottentomatoes_train[\"label_text\"] = df_rottentomatoes_train.label.map(label_mapping_rottentomatoes)\n",
        "df_rottentomatoes_train[\"label_text\"] = df_rottentomatoes_train[\"label_text\"].map({\"neg\": \"negative\", \"pos\": \"positive\"})\n",
        "\n",
        "df_rottentomatoes_train = df_rottentomatoes_train[~df_rottentomatoes_train.text.duplicated()]\n",
        "\n",
        "df_rottentomatoes_train[\"label_standard\"] = df_rottentomatoes_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_rottentomatoes_train))\n",
        "n_data_per_label = 10_000\n",
        "df_rottentomatoes_train = df_rottentomatoes_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length before downsampling: \", len(df_rottentomatoes_train))\n",
        "\n",
        "# final harmonized format\n",
        "df_rottentomatoes_train = df_rottentomatoes_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_rottentomatoes_train.label_text.value_counts())\n",
        "display(df_rottentomatoes_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ANvz4yaLNoZ"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "df_rottentomatoes_test = dataset_rottentomatoes[\"test\"].to_pandas()\n",
        "df_rottentomatoes_test[\"label_text\"] = df_rottentomatoes_test.label.map(label_mapping_rottentomatoes)\n",
        "df_rottentomatoes_test[\"label_text\"] = df_rottentomatoes_test[\"label_text\"].map({\"neg\": \"negative\", \"pos\": \"positive\"})\n",
        "df_rottentomatoes_test[\"label_standard\"] = df_rottentomatoes_test.label_text.factorize(sort=True)[0]\n",
        "df_rottentomatoes_test = df_rottentomatoes_test[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "display(df_rottentomatoes_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbibp_4BLNoZ"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"rottentomatoes\"\n",
        "df_rottentomatoes_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_rottentomatoes_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9OiylxSIq-a"
      },
      "source": [
        "#### Amazon polarity dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQoOHBKcHokq"
      },
      "outputs": [],
      "source": [
        "dataset_amazonpolarity = load_dataset(\"amazon_polarity\")\n",
        "print(\"Raw dataset structure:\\n\", dataset_amazonpolarity)\n",
        "\n",
        "# merge title and content for text column\n",
        "dataset_amazonpolarity = dataset_amazonpolarity.map(lambda x: {\"text\": x[\"title\"] + \"\\n\" + x[\"content\"]})\n",
        "\n",
        "label_mapping_amazonpolarity = {\n",
        "    idx: name for idx, name in enumerate(dataset_amazonpolarity[\"train\"].features[\"label\"].names)\n",
        "}\n",
        "\n",
        "## prepare df_train\n",
        "df_amazonpolarity_train = dataset_amazonpolarity[\"train\"].to_pandas()\n",
        "\n",
        "df_amazonpolarity_train[\"label_text\"] = df_amazonpolarity_train.label.map(label_mapping_amazonpolarity)\n",
        "\n",
        "df_amazonpolarity_train = df_amazonpolarity_train[~df_amazonpolarity_train.text.duplicated()]\n",
        "\n",
        "df_amazonpolarity_train[\"label_standard\"] = df_amazonpolarity_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_amazonpolarity_train))\n",
        "n_data_per_label = 10_000\n",
        "df_amazonpolarity_train = df_amazonpolarity_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length before downsampling: \", len(df_amazonpolarity_train))\n",
        "\n",
        "# final harmonized format\n",
        "df_amazonpolarity_train = df_amazonpolarity_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_amazonpolarity_train.label_text.value_counts())\n",
        "display(df_amazonpolarity_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFgI5KtkHokq"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "df_amazonpolarity_test = dataset_amazonpolarity[\"test\"].to_pandas()\n",
        "df_amazonpolarity_test[\"label_text\"] = df_amazonpolarity_test.label.map(label_mapping_amazonpolarity)\n",
        "df_amazonpolarity_test[\"label_standard\"] = df_amazonpolarity_test.label_text.factorize(sort=True)[0]\n",
        "df_amazonpolarity_test = df_amazonpolarity_test[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "display(df_amazonpolarity_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqWPDlyDHokr"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"amazonpolarity\"\n",
        "df_amazonpolarity_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_amazonpolarity_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F6uz3C4L3jK"
      },
      "source": [
        "#### IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gna08PAbGAZ1"
      },
      "outputs": [],
      "source": [
        "dataset_imdb = load_dataset(\"imdb\")\n",
        "print(\"Raw dataset structure:\\n\", dataset_imdb)\n",
        "\n",
        "label_mapping_imdb = {\n",
        "    idx: name for idx, name in enumerate(dataset_imdb[\"train\"].features[\"label\"].names)\n",
        "}\n",
        "\n",
        "## prepare df_train\n",
        "df_imdb_train = dataset_imdb[\"train\"].to_pandas()\n",
        "\n",
        "df_imdb_train[\"label_text\"] = df_imdb_train.label.map(label_mapping_imdb)\n",
        "\n",
        "df_imdb_train[\"label_text\"] = df_imdb_train[\"label_text\"].map({\"pos\": \"positive\", \"neg\": \"negative\"})\n",
        "\n",
        "df_imdb_train = df_imdb_train[~df_imdb_train.text.duplicated()]\n",
        "\n",
        "df_imdb_train[\"label_standard\"] = df_imdb_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_imdb_train))\n",
        "n_data_per_label = 10_000\n",
        "df_imdb_train = df_imdb_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length before downsampling: \", len(df_imdb_train))\n",
        "\n",
        "# final harmonized format\n",
        "df_imdb_train = df_imdb_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_imdb_train.label_text.value_counts())\n",
        "display(df_imdb_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cJ0CxTCGAZ2"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "df_imdb_test = dataset_imdb[\"test\"].to_pandas()\n",
        "df_imdb_test[\"label_text\"] = df_imdb_test.label.map(label_mapping_imdb)\n",
        "df_imdb_test[\"label_text\"] = df_imdb_test[\"label_text\"].map({\"pos\": \"positive\", \"neg\": \"negative\"})\n",
        "df_imdb_test[\"label_standard\"] = df_imdb_test.label_text.factorize(sort=True)[0]\n",
        "df_imdb_test = df_imdb_test[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "display(df_imdb_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTGE5srNGAZ2"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"imdb\"\n",
        "df_imdb_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_imdb_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXWHyDQRcxXH"
      },
      "source": [
        "#### App Reviews dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMXcG-Gj_Bz5"
      },
      "outputs": [],
      "source": [
        "dataset_appreviews = load_dataset(\"app_reviews\")\n",
        "# only has train set\n",
        "print(\"Raw dataset structure:\\n\", dataset_appreviews)\n",
        "\n",
        "# remove very short reviews\n",
        "dataset_appreviews['train'] = dataset_appreviews['train'].filter(lambda x: len(x[\"review\"]) >= 100 and len(x[\"review\"]) <= 1500)\n",
        "\n",
        "df_appreviews_train = dataset_appreviews[\"train\"].to_pandas()\n",
        "\n",
        "# convert 5-star scale into binary task, because only silver labels\n",
        "def label_mapping_appreviews(label):\n",
        "    # star range: 1 - 5\n",
        "    if label == 5:\n",
        "        label_text = \"positive\"\n",
        "    elif label <= 2:\n",
        "        label_text = \"negative\"\n",
        "    elif (label == 3) or (label == 4):\n",
        "        # too unclear / culture dependent what 3 or 4 stars represent\n",
        "        label_text = None  #\"mixed\"\n",
        "    else:\n",
        "        raise Exception(\"Something went wrong when translating numeric to verbal labels\")\n",
        "\n",
        "    return label_text\n",
        "\n",
        "\n",
        "df_appreviews_train[\"label_text\"] = df_appreviews_train.star.map(\n",
        "    lambda example: label_mapping_appreviews(example)\n",
        ")\n",
        "df_appreviews_train = df_appreviews_train[df_appreviews_train.label_text != None]\n",
        "\n",
        "df_appreviews_train = df_appreviews_train.rename(columns={\"review\": \"text\"})\n",
        "df_appreviews_train = df_appreviews_train[~df_appreviews_train.text.duplicated()]\n",
        "\n",
        "df_appreviews_train[\"label_standard\"] = df_appreviews_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_appreviews_train))\n",
        "n_data_per_label = 10_000\n",
        "df_appreviews_train = df_appreviews_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length after downsampling: \", len(df_appreviews_train))\n",
        "\n",
        "# final harmonized format\n",
        "df_appreviews_train = df_appreviews_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_appreviews_train.label_text.value_counts())\n",
        "display(df_appreviews_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SmCRyGv5SXc"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "# no test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_appreviews_train_split, df_appreviews_test_split = train_test_split(\n",
        "    df_appreviews_train, test_size=0.2, random_state=SEED_GLOBAL,\n",
        "    shuffle=True, stratify=df_appreviews_train[\"label_text\"]\n",
        ")\n",
        "print(len(df_appreviews_train_split))\n",
        "print(len(df_appreviews_test_split))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtr72OsT5SXd"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"appreviews\"\n",
        "df_appreviews_train_split.reset_index(drop=True).to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_appreviews_test_split.reset_index(drop=True).to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B84wTOgOiXVY"
      },
      "source": [
        "#### Yelp review dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_yd0-k66PDH"
      },
      "outputs": [],
      "source": [
        "dataset_yelpreviews = load_dataset(\"yelp_review_full\")\n",
        "print(\"Raw dataset structure:\\n\", dataset_yelpreviews)\n",
        "\n",
        "## prepare df_train\n",
        "df_yelpreviews_train = dataset_yelpreviews[\"train\"].to_pandas()\n",
        "\n",
        "# convert 5-star scale into binary task, because only silver labels\n",
        "def label_mapping_yelpreviews(label):\n",
        "    # star range: 0 - 4\n",
        "    if label == 4:\n",
        "        label_text = \"positive\"\n",
        "    elif label <= 1:\n",
        "        label_text = \"negative\"\n",
        "    elif (label == 2) or (label == 3):\n",
        "        # too unclear / culture dependent what 2 or 3 stars~ represent\n",
        "        label_text = None  #\"mixed\"\n",
        "    else:\n",
        "        raise Exception(\"Something went wrong when translating numeric to verbal labels\")\n",
        "\n",
        "    return label_text\n",
        "\n",
        "\n",
        "df_yelpreviews_train[\"label_text\"] = df_yelpreviews_train.label.map(\n",
        "    lambda example: label_mapping_yelpreviews(example)\n",
        ")\n",
        "df_yelpreviews_train = df_yelpreviews_train[df_yelpreviews_train.label_text != None]\n",
        "\n",
        "df_yelpreviews_train = df_yelpreviews_train[~df_yelpreviews_train.text.duplicated()]\n",
        "\n",
        "df_yelpreviews_train[\"label_standard\"] = df_yelpreviews_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_yelpreviews_train))\n",
        "n_data_per_label = 10_000\n",
        "df_yelpreviews_train = df_yelpreviews_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length before downsampling: \", len(df_yelpreviews_train))\n",
        "\n",
        "# final harmonized format\n",
        "df_yelpreviews_train = df_yelpreviews_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_yelpreviews_train.label_text.value_counts())\n",
        "display(df_yelpreviews_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWTv_GI96PDI"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "df_yelpreviews_test = dataset_yelpreviews[\"test\"].to_pandas()\n",
        "df_yelpreviews_test[\"label_text\"] = df_yelpreviews_test.label.map(\n",
        "    lambda example: label_mapping_yelpreviews(example)\n",
        ")\n",
        "df_yelpreviews_test = df_yelpreviews_train[df_yelpreviews_test.label_text != None]\n",
        "\n",
        "df_yelpreviews_test[\"label_standard\"] = df_yelpreviews_test.label_text.factorize(sort=True)[0]\n",
        "df_yelpreviews_test = df_yelpreviews_test[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "display(df_yelpreviews_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EdHxSD46PDI"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"yelpreviews\"\n",
        "df_yelpreviews_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_yelpreviews_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT432_t4hywK"
      },
      "source": [
        "#### Wiki Toxic dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FLPcExEpOg4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import DatasetDict, Dataset\n",
        "\n",
        "# hf version aggregated relevant sub-tasks. I'm using the original data instead\n",
        "#from datasets import load_dataset\n",
        "#dataset_wiki_toxic = load_dataset(\"OxAISH-AL-LLM/wiki_toxic\")\n",
        "#dataset_wiki_toxic[\"balanced_train\"].to_pandas().head()\n",
        "\n",
        "# data source: https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data\n",
        "df_wiki_toxic_train = pd.read_csv(\"./datasets_raw/wiki_toxic_train.csv.zip\")\n",
        "df_wiki_toxic_train = df_wiki_toxic_train.rename(columns={\"comment_text\": \"text\"})\n",
        "\n",
        "# df_test merge texts with labels\n",
        "df_wiki_toxic_test1 = pd.read_csv(\"./datasets_raw/wiki_toxic_test_labels.csv.zip\")\n",
        "df_wiki_toxic_test2 = pd.read_csv(\"./datasets_raw/wiki_toxic_test.csv.zip\")\n",
        "df_wiki_toxic_test = df_wiki_toxic_test2.merge(df_wiki_toxic_test1, on=\"id\")\n",
        "# remove unannotated texts (indicated by -1 label)\n",
        "df_wiki_toxic_test = df_wiki_toxic_test[df_wiki_toxic_test[\"toxic\"] != -1].reset_index(drop=True)\n",
        "df_wiki_toxic_test = df_wiki_toxic_test.rename(columns={\"comment_text\": \"text\"})\n",
        "\n",
        "# aggregate the toxic and severe_toxic labels into one label\n",
        "df_wiki_toxic_train[\"toxicaggregated\"] = [1 if (toxic == 1) or (severe_toxic == 1) else 0 for toxic, severe_toxic in zip(df_wiki_toxic_train.toxic, df_wiki_toxic_train.severe_toxic)]\n",
        "df_wiki_toxic_test[\"toxicaggregated\"] = [1 if (toxic == 1) or (severe_toxic == 1) else 0 for toxic, severe_toxic in zip(df_wiki_toxic_test.toxic, df_wiki_toxic_test.severe_toxic)]\n",
        "\n",
        "df_wiki_toxic_train = df_wiki_toxic_train.rename(columns={\"identity_hate\": \"identityhate\"})\n",
        "df_wiki_toxic_test = df_wiki_toxic_test.rename(columns={\"identity_hate\": \"identityhate\"})\n",
        "\n",
        "# careful: the dataset is multilabel\n",
        "# I convert it to multiple different binary tasks\n",
        "df_wiki_toxic_dic = {}\n",
        "for col in [\"toxicaggregated\", \"obscene\", \"threat\", \"insult\", \"identityhate\"]:\n",
        "    # train\n",
        "    # take balanced sample. \"Other\" class is much bigger (label 0). reduce it to 2 * size of positive class (label 1).\n",
        "    len_positive_class = 2*len(df_wiki_toxic_train[df_wiki_toxic_train[col] == 1])\n",
        "    max_sample = len_positive_class if len_positive_class < 10_000 else 10_000\n",
        "    df_wiki_toxic_train_col_balanced = df_wiki_toxic_train.groupby(col, as_index=False, group_keys=False).apply(lambda x: x.sample(min(len(x), max_sample), random_state=SEED_GLOBAL))\n",
        "    # add label_text col\n",
        "    df_wiki_toxic_train_col_balanced.loc[df_wiki_toxic_train_col_balanced[col] == 1, \"label_text\"] = col\n",
        "    df_wiki_toxic_train_col_balanced.loc[df_wiki_toxic_train_col_balanced[col] == 0, \"label_text\"] = \"not_\" + col\n",
        "    df_wiki_toxic_train_col_balanced = df_wiki_toxic_train_col_balanced[[\"text\", \"label_text\", col]].rename(columns={col: \"label_standard\"}).reset_index(drop=True)\n",
        "    df_wiki_toxic_train_col_balanced = df_wiki_toxic_train_col_balanced.sample(frac=1, random_state=SEED_GLOBAL)\n",
        "    # test\n",
        "    df_wiki_toxic_test_col = df_wiki_toxic_test\n",
        "    # add label_text col\n",
        "    df_wiki_toxic_test_col.loc[df_wiki_toxic_test_col[col] == 1, \"label_text\"] = col\n",
        "    df_wiki_toxic_test_col.loc[df_wiki_toxic_test_col[col] == 0, \"label_text\"] = \"not_\" + col\n",
        "    df_wiki_toxic_test_col = df_wiki_toxic_test_col[[\"text\", \"label_text\", col]].rename(columns={col: \"label_standard\"}).reset_index(drop=True)\n",
        "    # append to dic\n",
        "    df_wiki_toxic_dic.update({col: {\"train\": df_wiki_toxic_train_col_balanced, \"test\": df_wiki_toxic_test_col}})\n",
        "    print(\"Label distribution in dataset:\\n\", df_wiki_toxic_train_col_balanced.label_text.value_counts(), \"\\n\")\n",
        "\n",
        "# show example data\n",
        "display(df_wiki_toxic_dic[\"toxicaggregated\"][\"train\"].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbi66HMAc04H"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"wikitoxic\"\n",
        "for col in [\"toxicaggregated\", \"obscene\", \"threat\", \"insult\", \"identityhate\"]:\n",
        "    df_wiki_toxic_dic[col][\"train\"].to_parquet(f\"./datasets_standardized/ds_{dataset_name}_{col}_train.gzip\", compression='gzip')\n",
        "    df_wiki_toxic_dic[col][\"test\"].to_parquet(f\"./datasets_standardized/ds_{dataset_name}_{col}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoNQAjMgc3Pa"
      },
      "source": [
        "#### Hate Speech Offensive dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P34w95mnf3hX"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_hate_offensive = load_dataset(\"hate_speech_offensive\")\n",
        "# dataset only has train split\n",
        "print(\"Raw dataset structure:\\n\", dataset_hate_offensive)\n",
        "\n",
        "df_hate_offensive_train = dataset_hate_offensive[\"train\"].to_pandas()\n",
        "\n",
        "# only keep rows where at least 3 annotators agreed on same label\n",
        "df_hate_offensive_train = df_hate_offensive_train[\n",
        "    (df_hate_offensive_train.hate_speech_count >= 3) |\n",
        "    (df_hate_offensive_train.offensive_language_count >= 3) |\n",
        "    (df_hate_offensive_train.neither_count >= 3)\n",
        "]\n",
        "print(\"Number of texts after selecting higher quality: \", len(df_hate_offensive_train))\n",
        "\n",
        "# clean html tags\n",
        "import html\n",
        "df_hate_offensive_train['tweet'] = df_hate_offensive_train['tweet'].apply(html.unescape)\n",
        "\n",
        "df_hate_offensive_train = df_hate_offensive_train.rename(columns={\"tweet\": \"text\"})\n",
        "\n",
        "df_hate_offensive_train = df_hate_offensive_train[~df_hate_offensive_train.text.duplicated()]\n",
        "\n",
        "label_text_map_hate_offensive = {0: \"hate_speech\", 1: \"offensive\", 2: \"neither\"}\n",
        "df_hate_offensive_train[\"label_text\"] = df_hate_offensive_train[\"class\"].map(label_text_map_hate_offensive)\n",
        "\n",
        "df_hate_offensive_train[\"label_standard\"] = df_hate_offensive_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "df_hate_offensive_train = df_hate_offensive_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "# highly imbalanced - downsample\n",
        "print(\"Label distribution in dataset before downsampling:\\n\", df_hate_offensive_train.label_text.value_counts())\n",
        "max_per_label = 2000\n",
        "df_hate_offensive_train = df_hate_offensive_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(lambda x: x.sample(n=min(max_per_label, len(x)), random_state=SEED_GLOBAL)).reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_hate_offensive_train.label_text.value_counts())\n",
        "display(df_hate_offensive_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7Phw0IJ5ylh"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "# no test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_hate_offensive_train_split, df_hate_offensive_test_split = train_test_split(\n",
        "    df_hate_offensive_train, test_size=0.2, random_state=SEED_GLOBAL,\n",
        "    shuffle=True, stratify=df_hate_offensive_train[\"label_text\"]\n",
        ")\n",
        "print(len(df_hate_offensive_train_split))\n",
        "print(len(df_hate_offensive_test_split))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaM0qJO75ylh"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"hateoffensive\"\n",
        "df_hate_offensive_train_split.reset_index(drop=True).to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_hate_offensive_test_split.reset_index(drop=True).to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlv_G2xcr7sX"
      },
      "source": [
        "#### HateXplain dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3Uotk6pu1OY"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "dataset_hatexplain = load_dataset(\"hatexplain\")\n",
        "\n",
        "# merge train and val. not doing hp tuning\n",
        "df_hatexplain_train = pd.concat([\n",
        "    dataset_hatexplain[\"train\"].to_pandas(),\n",
        "    dataset_hatexplain[\"validation\"].to_pandas()\n",
        "])\n",
        "df_hatexplain_test = dataset_hatexplain[\"test\"].to_pandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cAfFN_Pvq6P"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "# extract only \"labels\" from dictionary in each cell\n",
        "df_hatexplain_train['label_original'] = df_hatexplain_train['annotators'].apply(lambda x: x['label'])\n",
        "df_hatexplain_test['label_original'] = df_hatexplain_test['annotators'].apply(lambda x: x['label'])\n",
        "\n",
        "# get consensus label\n",
        "def get_unique_value_if_all_same(x):\n",
        "    if all(item == x[0] for item in x):\n",
        "        return int(x[0])\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "df_hatexplain_train['label_original'] = df_hatexplain_train['label_original'].apply(get_unique_value_if_all_same)\n",
        "df_hatexplain_test['label_original'] = df_hatexplain_test['label_original'].apply(get_unique_value_if_all_same)\n",
        "\n",
        "print(len(df_hatexplain_train))\n",
        "df_hatexplain_train = df_hatexplain_train[~df_hatexplain_train['label_original'].isna()]\n",
        "df_hatexplain_test = df_hatexplain_test[~df_hatexplain_test['label_original'].isna()]\n",
        "print(len(df_hatexplain_train))\n",
        "\n",
        "# join text\n",
        "df_hatexplain_train[\"text\"] = df_hatexplain_train[\"post_tokens\"].apply(lambda x: \" \".join(x))\n",
        "df_hatexplain_test[\"text\"] = df_hatexplain_test[\"post_tokens\"].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# label map\n",
        "label_text_map_hatexplain = {\n",
        "    0: \"hate_speech\",\n",
        "    1: \"neither\",\n",
        "    2: \"offensive\",\n",
        "}\n",
        "df_hatexplain_train[\"label_text\"] = df_hatexplain_train[\"label_original\"].map(\n",
        "    label_text_map_hatexplain\n",
        ")\n",
        "df_hatexplain_test[\"label_text\"] = df_hatexplain_test[\"label_original\"].map(\n",
        "    label_text_map_hatexplain\n",
        ")\n",
        "\n",
        "df_hatexplain_train[\"label_standard\"] = df_hatexplain_train.label_text.factorize(sort=True)[0]\n",
        "df_hatexplain_test[\"label_standard\"] = df_hatexplain_test.label_text.factorize(sort=True)[0]\n",
        "\n",
        "\n",
        "# clean\n",
        "df_hatexplain_train = df_hatexplain_train[[\n",
        "    \"text\", \"label_text\", \"label_standard\", #\"id\", #\"annotators\", #\"rationales\", \"post_tokens\"\n",
        "]].reset_index(drop=True)\n",
        "df_hatexplain_test = df_hatexplain_test[[\n",
        "    \"text\", \"label_text\", \"label_standard\", #\"id\", #\"annotators\", #\"rationales\", \"post_tokens\"\n",
        "]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_hatexplain_train.label_text.value_counts())\n",
        "display(df_hatexplain_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVsCWT0WVavu"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"hatexplain\"\n",
        "df_hatexplain_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_hatexplain_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0b34OcS0owq"
      },
      "source": [
        "#### SMS Spam dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TyhNUPJJIrk"
      },
      "outputs": [],
      "source": [
        "dataset_spam = load_dataset(\"sms_spam\")\n",
        "print(\"Raw dataset structure:\\n\", dataset_spam)\n",
        "\n",
        "## prepare df_train\n",
        "df_spam_train = dataset_spam[\"train\"].to_pandas()\n",
        "\n",
        "label_text_map_spam = {0: \"not_spam\", 1: \"spam\"}\n",
        "df_spam_train[\"label_text\"] = df_spam_train.label.map(label_text_map_spam)\n",
        "\n",
        "df_spam_train = df_spam_train.rename(columns={\"sms\": \"text\"})\n",
        "df_spam_train = df_spam_train[~df_spam_train.text.duplicated()]\n",
        "\n",
        "df_spam_train[\"label_standard\"] = df_spam_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_spam_train))\n",
        "n_data_per_label = 10_000\n",
        "df_spam_train = df_spam_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length before downsampling: \", len(df_spam_train))\n",
        "\n",
        "# final harmonized format\n",
        "df_spam_train = df_spam_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_spam_train.label_text.value_counts())\n",
        "display(df_spam_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjrYc92x6mON"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "# no test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_spam_train_split, df_spam_test_split = train_test_split(\n",
        "    df_spam_train, test_size=0.2, random_state=SEED_GLOBAL,\n",
        "    shuffle=True, stratify=df_spam_train[\"label_text\"]\n",
        ")\n",
        "print(len(df_spam_train_split))\n",
        "print(len(df_spam_test_split))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ljnr5y_6mOO"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"spam\"\n",
        "df_spam_train_split.reset_index(drop=True).to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_spam_test_split.reset_index(drop=True).to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNSSZq7_3ivI"
      },
      "source": [
        "#### MASSIVE intent dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rOR2WuIHMvL"
      },
      "outputs": [],
      "source": [
        "dataset_massive = load_dataset(\"AmazonScience/massive\", \"en-US\")\n",
        "print(\"Raw dataset structure:\\n\", dataset_massive)\n",
        "\n",
        "# has two potential labels: scenario and intent. choosing the more fine-grained \"intent\"\n",
        "label_mapping_massive = {\n",
        "    idx: name for idx, name in enumerate(dataset_massive[\"train\"].features[\"intent\"].names)\n",
        "}\n",
        "\n",
        "## prepare df_train\n",
        "df_massive_train = pd.concat([\n",
        "    dataset_massive[\"train\"].to_pandas(),\n",
        "    dataset_massive[\"validation\"].to_pandas()\n",
        "])\n",
        "\n",
        "df_massive_train[\"label_text\"] = df_massive_train[\"intent\"].map(label_mapping_massive)\n",
        "\n",
        "df_massive_train[\"label_standard\"] = df_massive_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_massive_train))\n",
        "n_data_per_label = 10_000\n",
        "df_massive_train = df_massive_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length before downsampling: \", len(df_massive_train))\n",
        "\n",
        "# final harmonized format\n",
        "df_massive_train = df_massive_train.rename(columns={\"utt\": \"text\"})\n",
        "df_massive_train = df_massive_train[~df_massive_train.text.duplicated()]\n",
        "\n",
        "df_massive_train = df_massive_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_massive_train.label_text.value_counts())\n",
        "display(df_massive_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NPpvj9-HMvM"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "df_massive_test = dataset_massive[\"test\"].to_pandas()\n",
        "\n",
        "df_massive_test[\"label_text\"] = df_massive_test[\"intent\"].map(label_mapping_massive)\n",
        "df_massive_test[\"label_standard\"] = df_massive_test.label_text.factorize(sort=True)[0]\n",
        "\n",
        "df_massive_test = df_massive_test.rename(columns={\"utt\": \"text\"})\n",
        "df_massive_test = df_massive_test[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "display(df_massive_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AseT-bBRHMvM"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"massive\"\n",
        "df_massive_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_massive_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HapPhpQyrhyf"
      },
      "source": [
        "#### Banking77 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeWooMTXFgmV"
      },
      "outputs": [],
      "source": [
        "dataset_banking77 = load_dataset(\"PolyAI/banking77\")\n",
        "print(\"Raw dataset structure:\\n\", dataset_banking77)\n",
        "\n",
        "label_mapping_banking77 = {\n",
        "    idx: name for idx, name in enumerate(dataset_banking77[\"train\"].features[\"label\"].names)\n",
        "}\n",
        "\n",
        "## prepare df_train\n",
        "df_banking77_train = dataset_banking77[\"train\"].to_pandas()\n",
        "\n",
        "df_banking77_train[\"label_text\"] = df_banking77_train.label.map(label_mapping_banking77)\n",
        "\n",
        "df_banking77_train = df_banking77_train[~df_banking77_train.text.duplicated()]\n",
        "\n",
        "df_banking77_train[\"label_standard\"] = df_banking77_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_banking77_train))\n",
        "n_data_per_label = 10_000\n",
        "df_banking77_train = df_banking77_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length before downsampling: \", len(df_banking77_train))\n",
        "\n",
        "df_banking77_train = df_banking77_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_banking77_train.label_text.value_counts())\n",
        "display(df_banking77_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpijqzRsFgmW"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "df_banking77_test = dataset_banking77[\"test\"].to_pandas()\n",
        "df_banking77_test[\"label_text\"] = df_banking77_test.label.map(label_mapping_banking77)\n",
        "df_banking77_test[\"label_standard\"] = df_banking77_test.label_text.factorize(sort=True)[0]\n",
        "df_banking77_test = df_banking77_test[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "display(df_banking77_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9EE4NTRFgmW"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"banking77\"\n",
        "df_banking77_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_banking77_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9QQS1t8ixzK"
      },
      "source": [
        "#### emotion6 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyAvH5LcEu_c"
      },
      "outputs": [],
      "source": [
        "dataset_emotion_dair = load_dataset(\"dair-ai/emotion\")\n",
        "print(\"Raw dataset structure:\\n\", dataset_emotion_dair)\n",
        "\n",
        "label_mapping_emotion_dair = {\n",
        "    idx: name for idx, name in enumerate(dataset_emotion_dair[\"train\"].features[\"label\"].names)\n",
        "}\n",
        "\n",
        "## prepare df_train\n",
        "df_emotion_dair_train = pd.concat([\n",
        "    dataset_emotion_dair[\"train\"].to_pandas(),\n",
        "    dataset_emotion_dair[\"validation\"].to_pandas()\n",
        "])\n",
        "#df_emotion_dair_train = dataset_emotion_dair[\"train\"].to_pandas()\n",
        "\n",
        "df_emotion_dair_train[\"label_text\"] = df_emotion_dair_train.label.map(label_mapping_emotion_dair)\n",
        "\n",
        "df_emotion_dair_train = df_emotion_dair_train[~df_emotion_dair_train.text.duplicated()]\n",
        "\n",
        "df_emotion_dair_train[\"label_standard\"] = df_emotion_dair_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_emotion_dair_train))\n",
        "n_data_per_label = 10_000\n",
        "df_emotion_dair_train = df_emotion_dair_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length before downsampling: \", len(df_emotion_dair_train))\n",
        "\n",
        "\n",
        "df_emotion_dair_train = df_emotion_dair_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_emotion_dair_train.label_text.value_counts())\n",
        "display(df_emotion_dair_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgJlCdSXEu_d"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "df_emotion_dair_test = dataset_emotion_dair[\"test\"].to_pandas()\n",
        "df_emotion_dair_test[\"label_text\"] = df_emotion_dair_test.label.map(label_mapping_emotion_dair)\n",
        "df_emotion_dair_test[\"label_standard\"] = df_emotion_dair_test.label_text.factorize(sort=True)[0]\n",
        "df_emotion_dair_test = df_emotion_dair_test[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "display(df_emotion_dair_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE6yU9NMEu_d"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"emotiondair\"\n",
        "df_emotion_dair_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_emotion_dair_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76xCVaLhHWAH"
      },
      "source": [
        "#### EmoContextdataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug2KWhN7BI38"
      },
      "outputs": [],
      "source": [
        "dataset_emocontext = load_dataset(\"emo\")\n",
        "\n",
        "label_mapping_emocontext = {\n",
        "    idx: name for idx, name in enumerate(dataset_emocontext[\"train\"].features[\"label\"].names)\n",
        "}\n",
        "\n",
        "## prepare df_train\n",
        "df_emocontext_train = dataset_emocontext[\"train\"].to_pandas()\n",
        "\n",
        "df_emocontext_train[\"label_text\"] = df_emocontext_train.label.map(label_mapping_emocontext)\n",
        "\n",
        "df_emocontext_train = df_emocontext_train[~df_emocontext_train.text.duplicated()]\n",
        "\n",
        "df_emocontext_train[\"label_standard\"] = df_emocontext_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_emocontext_train))\n",
        "n_data_per_label = 10_000\n",
        "df_emocontext_train = df_emocontext_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length before downsampling: \", len(df_emocontext_train))\n",
        "\n",
        "df_emocontext_train = df_emocontext_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_emocontext_train.label_text.value_counts())\n",
        "display(df_emocontext_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3BvKOJeBI39"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "df_emocontext_test = dataset_emocontext[\"test\"].to_pandas()\n",
        "df_emocontext_test[\"label_text\"] = df_emocontext_test.label.map(label_mapping_emocontext)\n",
        "df_emocontext_test[\"label_standard\"] = df_emocontext_test.label_text.factorize(sort=True)[0]\n",
        "df_emocontext_test = df_emocontext_test[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "display(df_emocontext_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8GyTYK9BI39"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"emocontext\"\n",
        "df_emocontext_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_emocontext_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM5SBvU-kEEV"
      },
      "source": [
        "#### Empathetic Dialogue dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHVcJFYWkH2m"
      },
      "outputs": [],
      "source": [
        "# ! Challenge with dataset: is effectively multi-label. NLI augmentation can lead to errors\n",
        "# strongly cleaning and downsampling to reduce risk\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset_empathetic = load_dataset(\"empathetic_dialogues\")\n",
        "print(dataset_empathetic)\n",
        "\n",
        "df_empathetic_train = pd.concat([\n",
        "    dataset_empathetic[\"train\"].to_pandas(),\n",
        "    dataset_empathetic[\"validation\"].to_pandas()\n",
        "])\n",
        "\n",
        "def merge_dialogues(example):\n",
        "    dialogue = \"Context: \" + example[\"prompt\"].iloc[0]\n",
        "    first_speaker = True\n",
        "    for utterance in example[\"utterance\"].to_list():\n",
        "        if first_speaker:\n",
        "            dialogue += f\"\\nSpeaker 1: {utterance}\"\n",
        "        else:\n",
        "            dialogue += f\"\\nSpeaker 2: {utterance}\"\n",
        "        first_speaker = not first_speaker\n",
        "\n",
        "    dialogue = dialogue.replace(\"_comma_\", \",\")\n",
        "\n",
        "    return pd.Series({\"text\": dialogue, \"label_text\": example[\"context\"].iloc[0]})\n",
        "\n",
        "\n",
        "df_empathetic_train = df_empathetic_train.groupby(by=\"conv_id\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: merge_dialogues(x)\n",
        ")\n",
        "df_empathetic_train = df_empathetic_train[~df_empathetic_train.text.duplicated()]\n",
        "df_empathetic_train = df_empathetic_train.drop(columns=[\"conv_id\"])\n",
        "df_empathetic_train = df_empathetic_train.reset_index(drop=True)\n",
        "\n",
        "df_empathetic_train[\"label_standard\"] = df_empathetic_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_empathetic_train.label_text.value_counts())\n",
        "\n",
        "display(df_empathetic_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHrcyL_dCrCp"
      },
      "outputs": [],
      "source": [
        "df_empathetic_test = dataset_empathetic[\"test\"].to_pandas()\n",
        "\n",
        "df_empathetic_test = df_empathetic_test.groupby(by=\"conv_id\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: merge_dialogues(x)\n",
        ")\n",
        "\n",
        "df_empathetic_test = df_empathetic_test[~df_empathetic_test.text.duplicated()]\n",
        "df_empathetic_test = df_empathetic_test.drop(columns=[\"conv_id\"])\n",
        "df_empathetic_test = df_empathetic_test.reset_index(drop=True)\n",
        "\n",
        "df_empathetic_test[\"label_standard\"] = df_empathetic_test.label_text.factorize(sort=True)[0]\n",
        "\n",
        "display(df_empathetic_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHapTGtBDLPK"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"empathetic\"\n",
        "df_empathetic_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_empathetic_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIU1a4LL-dPp"
      },
      "source": [
        "#### agnews dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgt-4m50_24g"
      },
      "outputs": [],
      "source": [
        "dataset_agnews = load_dataset(\"ag_news\")\n",
        "\n",
        "label_mapping_agnews = {\n",
        "    idx: name for idx, name in enumerate(dataset_agnews[\"train\"].features[\"label\"].names)\n",
        "}\n",
        "\n",
        "## prepare df_train\n",
        "df_agnews_train = pd.concat([\n",
        "    dataset_agnews[\"train\"].to_pandas(),\n",
        "    dataset_agnews[\"test\"].to_pandas()\n",
        "])\n",
        "#df_agnews_train = dataset_agnews[\"train\"].to_pandas()\n",
        "\n",
        "df_agnews_train[\"label_text\"] = df_agnews_train.label.map(label_mapping_agnews)\n",
        "\n",
        "df_agnews_train = df_agnews_train[~df_agnews_train.text.duplicated()]\n",
        "\n",
        "df_agnews_train[\"label_standard\"] = df_agnews_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_agnews_train))\n",
        "n_data_per_label = 10_000\n",
        "df_agnews_train = df_agnews_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length before downsampling: \", len(df_agnews_train))\n",
        "\n",
        "\n",
        "df_agnews_train = df_agnews_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_agnews_train.label_text.value_counts())\n",
        "display(df_agnews_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkAxzLsa_24h"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "df_agnews_test = dataset_agnews[\"test\"].to_pandas()\n",
        "df_agnews_test[\"label_text\"] = df_agnews_test.label.map(label_mapping_agnews)\n",
        "df_agnews_test[\"label_standard\"] = df_agnews_test.label_text.factorize(sort=True)[0]\n",
        "df_agnews_test = df_agnews_test[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "display(df_agnews_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHht1vfv_24h"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"agnews\"\n",
        "df_agnews_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_agnews_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLml3NT9B7uL"
      },
      "source": [
        "#### Yahoo answers topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6_CgETpB-ex"
      },
      "outputs": [],
      "source": [
        "dataset_yahoo_topics = load_dataset(\"yahoo_answers_topics\")\n",
        "\n",
        "label_mapping_yahoo_topics = {\n",
        "    idx: name for idx, name in enumerate(dataset_yahoo_topics[\"train\"].features[\"topic\"].names)\n",
        "}\n",
        "\n",
        "df_yahoo_topics_train = dataset_yahoo_topics[\"train\"].to_pandas()\n",
        "\n",
        "df_yahoo_topics_train = df_yahoo_topics_train.rename(columns={\"topic\": \"label\"})\n",
        "df_yahoo_topics_train[\"text\"] = \"Question: \" + df_yahoo_topics_train[\"question_title\"] + \" \" + df_yahoo_topics_train[\"question_content\"] + \"\\n\\n\" + \"Answer: \" + df_yahoo_topics_train[\"best_answer\"]\n",
        "\n",
        "df_yahoo_topics_train[\"label_text\"] = df_yahoo_topics_train.label.map(label_mapping_yahoo_topics)\n",
        "df_yahoo_topics_train = df_yahoo_topics_train[~df_yahoo_topics_train.text.duplicated()]\n",
        "df_yahoo_topics_train[\"label_standard\"] = df_yahoo_topics_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# too large, downsample\n",
        "n_data_per_label = 10_000\n",
        "print(\"Dataset length before downsampling: \", len(df_yahoo_topics_train))\n",
        "df_yahoo_topics_train = df_yahoo_topics_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length after downsampling: \", len(df_yahoo_topics_train))\n",
        "\n",
        "\n",
        "df_yahoo_topics_train = df_yahoo_topics_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_yahoo_topics_train.label_text.value_counts())\n",
        "display(df_yahoo_topics_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKTs9QDeGd88"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "df_yahoo_topics_test = dataset_yahoo_topics[\"test\"].to_pandas()\n",
        "df_yahoo_topics_test = df_yahoo_topics_test.rename(columns={\"topic\": \"label\"})\n",
        "df_yahoo_topics_test[\"text\"] = \"Question: \" + df_yahoo_topics_test[\"question_title\"] + \" \" + df_yahoo_topics_test[\"question_content\"] + \"\\n\\n\" + \"Answer: \" + df_yahoo_topics_test[\"best_answer\"]\n",
        "\n",
        "df_yahoo_topics_test[\"label_text\"] = df_yahoo_topics_test.label.map(label_mapping_yahoo_topics)\n",
        "df_yahoo_topics_test[\"label_standard\"] = df_yahoo_topics_test.label_text.factorize(sort=True)[0]\n",
        "\n",
        "df_yahoo_topics_test = df_yahoo_topics_test[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "display(df_yahoo_topics_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u_Dy8Zb76gT"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"yahootopics\"\n",
        "df_yahoo_topics_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_yahoo_topics_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr3VkrfCeyGL"
      },
      "source": [
        "#### True Teacher dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: later train longer context model with non-shortened data"
      ],
      "metadata": {
        "id": "y3iL8RbIw3Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6fb2bnVpcZr"
      },
      "outputs": [],
      "source": [
        "## download data\n",
        "# paper: http://arxiv.org/abs/2305.11171\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# URL of the zip file\n",
        "url = \"https://storage.googleapis.com/gresearch/true_teacher/true_teacher_data.zip\"\n",
        "\n",
        "# Make a GET request to fetch the raw HTML content\n",
        "content = requests.get(url)\n",
        "\n",
        "# Open the content in memory\n",
        "zf = zipfile.ZipFile(BytesIO(content.content))\n",
        "\n",
        "# Assume that the JSON file is the first file in the zip\n",
        "print(zf.namelist())\n",
        "json_file_name_lst = ['true_teacher_data/t5-large.jsonl', 'true_teacher_data/t5-small.jsonl', 'true_teacher_data/t5-base.jsonl', 'true_teacher_data/t5-3b.jsonl', 'true_teacher_data/t5-11b.jsonl']\n",
        "\n",
        "# Open the JSON file\n",
        "df_trueteacher_lst = []\n",
        "for json_file_name in json_file_name_lst:\n",
        "    with zf.open(json_file_name) as f:\n",
        "        df_step = pd.read_json(f, lines=True)\n",
        "        df_step[\"model\"] = json_file_name.split(\"/\")[1].split(\".\")[0]\n",
        "        df_trueteacher_lst.append(df_step)\n",
        "\n",
        "df_trueteacher = pd.concat(df_trueteacher_lst)\n",
        "\n",
        "label_text_map_trueteacher = {0: \"factually_inconsistent\", 1: \"factually_consistent\"}\n",
        "df_trueteacher[\"label_text\"] = df_trueteacher.label.map(label_text_map_trueteacher)\n",
        "\n",
        "df_trueteacher.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1pPTJW0wMOW"
      },
      "outputs": [],
      "source": [
        "## merge with cnndm dataset to get full texts\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset_cnndm = load_dataset(\"cnn_dailymail\", '3.0.0')\n",
        "\n",
        "df_cnndm_train = pd.DataFrame({\n",
        "    \"cnndm_id\": dataset_cnndm[\"train\"][\"id\"],\n",
        "    \"article\": dataset_cnndm[\"train\"][\"article\"]\n",
        "})\n",
        "\n",
        "df_trueteacher_full = pd.merge(df_trueteacher, df_cnndm_train, on=\"cnndm_id\", how=\"inner\")\n",
        "print(len(df_trueteacher_full))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2Tq9t6X1HOh"
      },
      "outputs": [],
      "source": [
        "## True teacher does not seem to use cnndm test set\n",
        "# not sure how they created test set\n",
        "#df_cnndm_test = pd.DataFrame({\"cnndm_id\": dataset_cnndm[\"test\"][\"id\"], \"article\": dataset_cnndm[\"test\"][\"article\"]})\n",
        "#df_trueteacher_test = pd.merge(df_trueteacher, df_cnndm_test, on=\"cnndm_id\", how=\"inner\")\n",
        "#df_cnndm_validation = pd.DataFrame({\"cnndm_id\": dataset_cnndm[\"validation\"][\"id\"], \"article\": dataset_cnndm[\"validation\"][\"article\"]})\n",
        "#df_trueteacher_validation = pd.merge(df_trueteacher, df_cnndm_validation, on=\"cnndm_id\", how=\"inner\")\n",
        "#df_cnndm_validation.head()\n",
        "#print(len(df_trueteacher_test))\n",
        "#print(len(df_trueteacher_validation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D39Qzq8KAqPV"
      },
      "outputs": [],
      "source": [
        "# remove too long texts\n",
        "print(\"Text length distribution:\\n\", df_trueteacher_full.article.str.len().value_counts(bins=10))\n",
        "\n",
        "max_characters = 512 * 3\n",
        "df_trueteacher_short = df_trueteacher_full[(df_trueteacher_full.article.str.len() + df_trueteacher_full.summary.str.len()) < max_characters]\n",
        "label_distribution = df_trueteacher_short.label.value_counts()\n",
        "print(\"Raw label distribution (after truncation):\\n\", label_distribution)\n",
        "\n",
        "# sample for label balance\n",
        "df_trueteacher_short_samp = df_trueteacher_short.groupby(\n",
        "    \"label\", group_keys=False, as_index=False\n",
        "    ).apply(\n",
        "        lambda x: x.sample(n=label_distribution.min(), random_state=SEED_GLOBAL)\n",
        "    )\n",
        "# shuffle\n",
        "df_trueteacher_short_samp = df_trueteacher_short_samp.sample(\n",
        "    n=len(df_trueteacher_short_samp), random_state=SEED_GLOBAL\n",
        ")\n",
        "print(\"Downsampled balanced label distribution:\\n\", df_trueteacher_short_samp.label.value_counts())\n",
        "\n",
        "# input text formatting\n",
        "df_trueteacher_short_samp[\"text\"] = \"Summary:\\n\" + df_trueteacher_short_samp.summary + \"\\n\\nFull article:\\n\" + df_trueteacher_short_samp.article\n",
        "\n",
        "print(\"Number of texts before deduplication: \", len(df_trueteacher_short_samp))\n",
        "df_trueteacher_short_samp = df_trueteacher_short_samp[~df_trueteacher_short_samp.text.duplicated()]\n",
        "print(\"Number of texts after deduplication: \", len(df_trueteacher_short_samp))\n",
        "\n",
        "df_trueteacher_short_samp[\"label_standard\"] = df_trueteacher_short_samp.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# final format\n",
        "df_trueteacher_train = df_trueteacher_short_samp[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True).copy(deep=True)\n",
        "\n",
        "display(df_trueteacher_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jsJ3beD6Nlw"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "# no test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_trueteacher_train_split, df_trueteacher_test_split = train_test_split(\n",
        "    df_trueteacher_train, test_size=0.2, random_state=SEED_GLOBAL,\n",
        "    shuffle=True, stratify=df_trueteacher_train[\"label_text\"]\n",
        ")\n",
        "print(len(df_trueteacher_train_split))\n",
        "print(len(df_trueteacher_test_split))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLE_L3N_6Nlx"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"trueteacher\"\n",
        "df_trueteacher_train_split.reset_index(drop=True).to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_trueteacher_test_split.reset_index(drop=True).to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_5ARXfDtki9"
      },
      "source": [
        "#### Anthropic RLHF datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: later train longer context model with non-shortened data"
      ],
      "metadata": {
        "id": "R_MSrjo7tki9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDWiXRfxtki9"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
        "\n",
        "# dataset: https://huggingface.co/datasets/Anthropic/hh-rlhf\n",
        "# paper: https://arxiv.org/pdf/2204.05862.pdf\n",
        "# subsets described on p. 12\n",
        "dataset_anthropic_rlhf_helpful_base = load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"helpful-base\")\n",
        "dataset_anthropic_rlhf_helpful_rs = load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"helpful-rejection-sampled\")\n",
        "dataset_anthropic_rlhf_helpful_online = load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"helpful-online\")\n",
        "dataset_anthropic_rlhf_harmless = load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"harmless-base\")\n",
        "# not meant for preference modelling, different format, see: https://huggingface.co/datasets/Anthropic/hh-rlhf\n",
        "#dataset_anthropic_rlhf_redteam = load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"red-team-attempts\")\n",
        "\n",
        "dataset_anthropic_rlhf_helpful = DatasetDict({\n",
        "    \"train\": concatenate_datasets([\n",
        "        dataset_anthropic_rlhf_helpful_base[\"train\"],\n",
        "        dataset_anthropic_rlhf_helpful_rs[\"train\"],\n",
        "        dataset_anthropic_rlhf_helpful_online[\"train\"]\n",
        "    ]),\n",
        "    \"test\": concatenate_datasets([\n",
        "        dataset_anthropic_rlhf_helpful_base[\"test\"],\n",
        "        dataset_anthropic_rlhf_helpful_rs[\"test\"],\n",
        "        dataset_anthropic_rlhf_helpful_online[\"test\"]\n",
        "    ])\n",
        "})\n",
        "\n",
        "\n",
        "## specific dataset characteristics:\n",
        "# the same conversation can appear multiple times, only that new X conversation turns have been added\n",
        "#df_testing = dataset_anthropic_rlhf_redteam[\"train\"].to_pandas()[:100]\n",
        "#df_testing = df_testing[df_testing[\"chosen\"].str.contains(\"Human: How can I store food if I don't hav\")]\n",
        "\n",
        "print(\"dataset helpful: \", dataset_anthropic_rlhf_helpful)\n",
        "print(\"dataset harmless: \", dataset_anthropic_rlhf_harmless)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttYUhoyqtki-"
      },
      "outputs": [],
      "source": [
        "## tailored prompt\n",
        "import random\n",
        "\n",
        "\n",
        "def prompt_format_anthropic_rlhf(example, helpful_or_harmless=None, make_prompt_true=True):\n",
        "    np.random.seed(None)\n",
        "    chosen_first = random.choice([True, False])\n",
        "    positive_prompt = random.choice([True, False])\n",
        "\n",
        "    def prompt_format_correct(example, helpful_or_harmless=helpful_or_harmless, chosen_first=None, positive_prompt=None):\n",
        "        if chosen_first and positive_prompt:\n",
        "            #prompt_true = f\"\"\"First conversation:\\n{example[\"chosen\"]}\\n\\nSecond conversation:\\n{example[\"rejected\"]}\n",
        "            #\\nThe assistant is more {helpful_or_harmless} in the first conversation.\n",
        "            #\"\"\"\n",
        "            text = f\"\"\"First conversation:\\n{example[\"chosen\"].strip()}\\n\\nSecond conversation:\\n{example[\"rejected\"].strip()}\"\"\"\n",
        "            hypothesis = f\"The assistant is more {helpful_or_harmless} in the first conversation.\"\n",
        "        elif chosen_first and not positive_prompt:\n",
        "            #prompt_true = f\"\"\"First conversation:\\n{example[\"chosen\"]}\\n\\nSecond conversation:\\n{example[\"rejected\"]}\n",
        "            #\\nThe assistant is less {helpful_or_harmless} in the second conversation.\n",
        "            #\"\"\"\n",
        "            text = f\"\"\"First conversation:\\n{example[\"chosen\"].strip()}\\n\\nSecond conversation:\\n{example[\"rejected\"].strip()}\"\"\"\n",
        "            hypothesis = f\"The assistant is less {helpful_or_harmless} in the second conversation.\"\n",
        "        elif not chosen_first and positive_prompt:\n",
        "            #prompt_true = f\"\"\"First conversation:\\n{example[\"rejected\"]}\\n\\nSecond conversation:\\n{example[\"chosen\"]}\n",
        "            #\\nThe assistant is more {helpful_or_harmless} in the second conversation.\n",
        "            #\"\"\"\n",
        "            text = f\"\"\"First conversation:\\n{example[\"rejected\"].strip()}\\n\\nSecond conversation:\\n{example[\"chosen\"].strip()}\"\"\"\n",
        "            hypothesis = f\"The assistant is more {helpful_or_harmless} in the second conversation.\"\n",
        "        elif not chosen_first and not positive_prompt:\n",
        "            #prompt_true = f\"\"\"First conversation:\\n{example[\"rejected\"]}\\n\\nSecond conversation:\\n{example[\"chosen\"]}\n",
        "            #\\nThe assistant is less {helpful_or_harmless} in the first conversation.\n",
        "            #\"\"\"\n",
        "            text = f\"\"\"First conversation:\\n{example[\"rejected\"].strip()}\\n\\nSecond conversation:\\n{example[\"chosen\"].strip()}\"\"\"\n",
        "            hypothesis = f\"The assistant is less {helpful_or_harmless} in the first conversation.\"\n",
        "        return text, hypothesis\n",
        "\n",
        "    def prompt_format_wrong(example, helpful_or_harmless=helpful_or_harmless, chosen_first=None, positive_prompt=None):\n",
        "        #simply flipped sequence of conversations\n",
        "        if chosen_first and positive_prompt:\n",
        "            #prompt_true = f\"\"\"First conversation:\\n{example[\"rejected\"]}\\n\\nSecond conversation:\\n{example[\"chosen\"]}\n",
        "            #\\nThe assistant is more {helpful_or_harmless} in the first conversation.\n",
        "            #\"\"\"\n",
        "            text = f\"\"\"First conversation:\\n{example[\"rejected\"].strip()}\\n\\nSecond conversation:\\n{example[\"chosen\"].strip()}\"\"\"\n",
        "            hypothesis = f\"The assistant is more {helpful_or_harmless} in the first conversation.\"\n",
        "        elif chosen_first and not positive_prompt:\n",
        "            #prompt_true = f\"\"\"First conversation:\\n{example[\"rejected\"]}\\n\\nSecond conversation:\\n{example[\"chosen\"]}\n",
        "            #\\nThe assistant is less {helpful_or_harmless} in the second conversation.\n",
        "            #\"\"\"\n",
        "            text = f\"\"\"First conversation:\\n{example[\"rejected\"].strip()}\\n\\nSecond conversation:\\n{example[\"chosen\"].strip()}\"\"\"\n",
        "            hypothesis = f\"The assistant is less {helpful_or_harmless} in the second conversation.\"\n",
        "        elif not chosen_first and positive_prompt:\n",
        "            #prompt_true = f\"\"\"First conversation:\\n{example[\"chosen\"]}\\n\\nSecond conversation:\\n{example[\"rejected\"]}\n",
        "            #\\nThe assistant is more {helpful_or_harmless} in the second conversation.\n",
        "            #\"\"\"\n",
        "            text = f\"\"\"First conversation:\\n{example[\"chosen\"].strip()}\\n\\nSecond conversation:\\n{example[\"rejected\"].strip()}\"\"\"\n",
        "            hypothesis = f\"The assistant is more {helpful_or_harmless} in the second conversation.\"\n",
        "        elif not chosen_first and not positive_prompt:\n",
        "            #prompt_true = f\"\"\"First conversation:\\n{example[\"chosen\"]}\\n\\nSecond conversation:\\n{example[\"rejected\"]}\n",
        "            #\\nThe assistant is less {helpful_or_harmless} in the first conversation.\n",
        "            #\"\"\"\n",
        "            text = f\"\"\"First conversation:\\n{example[\"chosen\"].strip()}\\n\\nSecond conversation:\\n{example[\"rejected\"].strip()}\"\"\"\n",
        "            hypothesis = f\"The assistant is less {helpful_or_harmless} in the first conversation.\"\n",
        "        return text, hypothesis\n",
        "\n",
        "    # create prompt\n",
        "    if make_prompt_true:\n",
        "        text, hypothesis = prompt_format_correct(example, helpful_or_harmless=helpful_or_harmless, chosen_first=chosen_first, positive_prompt=positive_prompt)\n",
        "    elif not make_prompt_true:\n",
        "        text, hypothesis = prompt_format_wrong(example, helpful_or_harmless=helpful_or_harmless, chosen_first=chosen_first, positive_prompt=positive_prompt)\n",
        "\n",
        "    label = 0 if make_prompt_true else 1\n",
        "\n",
        "    return {\"text\": text, \"labels\": label, \"label_text\": hypothesis, \"hypothesis\": hypothesis}\n",
        "\n",
        "\n",
        "# for each dataset (helpful & harmless) create two rows per text: one with correct label/hypothesis and one with false\n",
        "# helpful dataset\n",
        "dataset_anthropic_rlhf_helpful_true = dataset_anthropic_rlhf_helpful.map(\n",
        "    lambda example: prompt_format_anthropic_rlhf(\n",
        "        example, helpful_or_harmless=\"helpful and honest\",\n",
        "        make_prompt_true=True\n",
        "    )\n",
        ")\n",
        "dataset_anthropic_rlhf_helpful_false = dataset_anthropic_rlhf_helpful.map(\n",
        "    lambda example: prompt_format_anthropic_rlhf(\n",
        "        example, helpful_or_harmless=\"helpful and honest\",\n",
        "        make_prompt_true=False\n",
        "    )\n",
        ")\n",
        "\n",
        "dataset_anthropic_rlhf_helpful_train = concatenate_datasets([dataset_anthropic_rlhf_helpful_true[\"train\"], dataset_anthropic_rlhf_helpful_false[\"train\"]])\n",
        "dataset_anthropic_rlhf_helpful_test = concatenate_datasets([dataset_anthropic_rlhf_helpful_true[\"test\"], dataset_anthropic_rlhf_helpful_false[\"test\"]])\n",
        "dataset_anthropic_rlhf_helpful = DatasetDict({\"train\": dataset_anthropic_rlhf_helpful_train, \"test\": dataset_anthropic_rlhf_helpful_test})\n",
        "\n",
        "#dataset_anthropic_rlhf_helpful = dataset_anthropic_rlhf_helpful.remove_columns([\"chosen\", \"rejected\"])\n",
        "dataset_anthropic_rlhf_helpful = dataset_anthropic_rlhf_helpful.shuffle(seed=SEED_GLOBAL)\n",
        "\n",
        "# harmless dataset\n",
        "dataset_anthropic_rlhf_harmless_true = dataset_anthropic_rlhf_harmless.map(\n",
        "    lambda example: prompt_format_anthropic_rlhf(\n",
        "        example, helpful_or_harmless=\"harmless\",\n",
        "        make_prompt_true=True\n",
        "    )\n",
        ")\n",
        "dataset_anthropic_rlhf_harmless_false = dataset_anthropic_rlhf_harmless.map(\n",
        "    lambda example: prompt_format_anthropic_rlhf(\n",
        "        example, helpful_or_harmless=\"harmless\",\n",
        "        make_prompt_true=False\n",
        "    )\n",
        ")\n",
        "dataset_anthropic_rlhf_harmless_train = concatenate_datasets([dataset_anthropic_rlhf_harmless_true[\"train\"], dataset_anthropic_rlhf_harmless_false[\"train\"]])\n",
        "dataset_anthropic_rlhf_harmless_test = concatenate_datasets([dataset_anthropic_rlhf_harmless_true[\"test\"], dataset_anthropic_rlhf_harmless_false[\"test\"]])\n",
        "dataset_anthropic_rlhf_harmless = DatasetDict({\"train\": dataset_anthropic_rlhf_harmless_train, \"test\": dataset_anthropic_rlhf_harmless_test})\n",
        "\n",
        "dataset_anthropic_rlhf_harmless = dataset_anthropic_rlhf_harmless.shuffle(seed=SEED_GLOBAL)\n",
        "\n",
        "# inspect results\n",
        "print(\"Label distribution harmless\\n\", dataset_anthropic_rlhf_harmless[\"train\"].to_pandas().labels.value_counts(), \"\\n\")\n",
        "print(\"Label distribution helpful\\n\", dataset_anthropic_rlhf_helpful[\"train\"].to_pandas().labels.value_counts(), \"\\n\")\n",
        "\n",
        "display(dataset_anthropic_rlhf_harmless[\"train\"].to_pandas().head(100))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shorten datasets if too long\n",
        "print(\"Length harmless before shortening: \", dataset_anthropic_rlhf_harmless)\n",
        "print(\"Length helpful before shortening: \", dataset_anthropic_rlhf_helpful)\n",
        "\n",
        "max_characters = 512 * 3\n",
        "dataset_anthropic_rlhf_harmless = dataset_anthropic_rlhf_harmless.filter(lambda x: len(x[\"text\"]) >= 100 and len(x[\"text\"]) <= max_characters)\n",
        "dataset_anthropic_rlhf_helpful = dataset_anthropic_rlhf_helpful.filter(lambda x: len(x[\"text\"]) >= 100 and len(x[\"text\"]) <= max_characters)\n",
        "\n",
        "print(\"\\nLength harmless after shortening: \", dataset_anthropic_rlhf_harmless)\n",
        "print(\"Length helpful after shortening: \", dataset_anthropic_rlhf_helpful)\n"
      ],
      "metadata": {
        "id": "giZnwTFJvSxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03BtmTSztki-"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_anthropic_rlhf_harmless[\"train\"].to_pandas().to_parquet(f\"./datasets_standardized/ds_anthropic_harmless_train.gzip\", compression='gzip')\n",
        "dataset_anthropic_rlhf_harmless[\"test\"].to_pandas().to_parquet(f\"./datasets_standardized/ds_anthropic_harmless_test.gzip\", compression='gzip')\n",
        "\n",
        "dataset_anthropic_rlhf_helpful[\"train\"].to_pandas().to_parquet(f\"./datasets_standardized/ds_anthropic_helpful_train.gzip\", compression='gzip')\n",
        "dataset_anthropic_rlhf_helpful[\"test\"].to_pandas().to_parquet(f\"./datasets_standardized/ds_anthropic_helpful_test.gzip\", compression='gzip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoHAXnL972ID"
      },
      "source": [
        "### New Dataset template\n",
        "Below is copy-paste able code for adding new datasets. Datasets may beed some custom wrangling/cleaning, so make sure to inspect the data and adapt the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efSZuxXBIscR"
      },
      "outputs": [],
      "source": [
        "assert 1 == 2, \"Block following code from executing when running entire notebook\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BveFC51J7461"
      },
      "outputs": [],
      "source": [
        "dataset_XXX = load_dataset(\"XXX\")\n",
        "print(\"Raw dataset structure:\\n\", dataset_XXX)\n",
        "\n",
        "label_mapping_XXX = {\n",
        "    idx: name for idx, name in enumerate(dataset_XXX[\"train\"].features[\"label\"].names)\n",
        "}\n",
        "\n",
        "## prepare df_train\n",
        "df_XXX_train = pd.concat([\n",
        "    dataset_XXX[\"train\"].to_pandas(),\n",
        "    dataset_XXX[\"validation\"].to_pandas()\n",
        "])\n",
        "\n",
        "df_XXX_train[\"label_text\"] = df_XXX_train.label.map(label_mapping_XXX)\n",
        "\n",
        "df_XXX_train = df_XXX_train[~df_XXX_train.text.duplicated()]\n",
        "\n",
        "df_XXX_train[\"label_standard\"] = df_XXX_train.label_text.factorize(sort=True)[0]\n",
        "\n",
        "# downsample if too large\n",
        "print(\"Dataset length before downsampling: \", len(df_XXX_train))\n",
        "n_data_per_label = 10_000\n",
        "df_XXX_train = df_XXX_train.groupby(\"label_text\", as_index=False, group_keys=False).apply(\n",
        "    lambda x: x.sample(min(n_data_per_label, len(x)), random_state=SEED_GLOBAL)\n",
        ")\n",
        "print(\"Dataset length after downsampling: \", len(df_XXX_train))\n",
        "\n",
        "# final harmonized format\n",
        "df_XXX_train = df_XXX_train[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Label distribution in dataset:\\n\", df_XXX_train.label_text.value_counts())\n",
        "display(df_XXX_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feH8kc6nGHTS"
      },
      "outputs": [],
      "source": [
        "## prepare df_test\n",
        "df_XXX_test = dataset_XXX[\"test\"].to_pandas()\n",
        "df_XXX_test[\"label_text\"] = df_XXX_test.label.map(label_mapping_XXX)\n",
        "df_XXX_test[\"label_standard\"] = df_XXX_test.label_text.factorize(sort=True)[0]\n",
        "df_XXX_test = df_XXX_test[[\"text\", \"label_text\", \"label_standard\"]].reset_index(drop=True)\n",
        "\n",
        "display(df_XXX_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lrKqZh-_Txi"
      },
      "outputs": [],
      "source": [
        "# save harmonized data to disk\n",
        "dataset_name = \"XXX\"\n",
        "df_XXX_train.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_train.gzip\", compression='gzip')\n",
        "df_XXX_test.to_parquet(f\"./datasets_standardized/ds_{dataset_name}_test.gzip\", compression='gzip')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}